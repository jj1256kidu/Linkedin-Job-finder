name: R&D Job Finder Update

on:
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours
  workflow_dispatch:  # Allows manual trigger
  push:
    branches: [ main ]
    paths:
      - 'scraper.py'
      - 'processor.py'
      - 'update_jobs.py'

jobs:
  update-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create credentials file
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
      run: |
        echo "$GOOGLE_CREDENTIALS" > credentials.json
    
    - name: Run job scraper
      id: scraper
      run: |
        python update_jobs.py
      continue-on-error: true
    
    - name: Notify on failure
      if: failure()
      uses: rtCamp/action-slack-notify@v2
      env:
        SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        SLACK_CHANNEL: alerts
        SLACK_COLOR: danger
        SLACK_TITLE: Job Scraper Failed
        SLACK_MESSAGE: 'Job scraper failed to update Google Sheet. Check the logs for details.'
    
    - name: Notify on success
      if: success()
      uses: rtCamp/action-slack-notify@v2
      env:
        SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        SLACK_CHANNEL: updates
        SLACK_COLOR: good
        SLACK_TITLE: Job Scraper Success
        SLACK_MESSAGE: 'Job scraper successfully updated Google Sheet with new data.'
    
    - name: Upload logs
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: scraper-logs
        path: |
          *.log
          scraper_output.txt 
