name: Update Job Listings

on:
  schedule:
    # Run every day at 8:00 AM UTC
    - cron: '0 8 * * *'
  # Allow manual triggering
  workflow_dispatch:

jobs:
  update-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install selenium beautifulsoup4 pandas geopy gspread oauth2client gspread-dataframe

    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser
        sudo apt-get install -y chromium-chromedriver

    - name: Create credentials file
      run: |
        echo '${{ secrets.GOOGLE_CREDENTIALS }}' > credentials.json

    - name: Run scraper
      run: |
        python scraper.py
      env:
        PYTHONPATH: ${{ github.workspace }}

    - name: Upload logs
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: scraper-logs
        path: |
          *.log
          *.csv
          *.json

    - name: Notify on failure
      if: failure()
      uses: rtCamp/action-slack-notify@v2
      env:
        SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        SLACK_CHANNEL: '#job-scraper'
        SLACK_COLOR: '#FF0000'
        SLACK_TITLE: 'Job Scraper Failed'
        SLACK_MESSAGE: 'Job scraper workflow failed. Check the logs for details.'
        SLACK_FOOTER: 'GitHub Actions'

    - name: Notify on success
      if: success()
      uses: rtCamp/action-slack-notify@v2
      env:
        SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        SLACK_CHANNEL: '#job-scraper'
        SLACK_COLOR: '#00FF00'
        SLACK_TITLE: 'Job Scraper Succeeded'
        SLACK_MESSAGE: 'Job scraper workflow completed successfully. Google Sheet has been updated.'
        SLACK_FOOTER: 'GitHub Actions' 
