name: Automated Job Scraper

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:  # Allow manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Run scraper
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
        run: |
          # Create credentials file
          echo "$GOOGLE_CREDENTIALS" > new-job-product-developeme-e8fedbafff68.json
          
          # Run the scraper
          python -c "from job_scraper import JobScraper; scraper = JobScraper(); scraper.run_scraper(['R&D', 'product development', 'innovation'], ['United States', 'Europe', 'Asia'], list(scraper.INDUSTRY_KEYWORDS.keys()))"
          
      - name: Commit and push changes
        run: |
          git config --global user.name 'GitHub Actions'
          git config --global user.email 'actions@github.com'
          git add .
          git commit -m "Update job listings [skip ci]"
          git push 
